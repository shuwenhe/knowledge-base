import streamlit as st
import os
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ”",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ” çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ")
st.markdown("---")

# ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.header("ğŸ“š ç³»ç»Ÿä¿¡æ¯")
    st.info("å½“å‰çŸ¥è¯†åº“ï¼šå…­é“å·¥åº")
    st.markdown("---")
    st.markdown("### ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„é—®é¢˜
    2. ç‚¹å‡»"æœç´¢"æŒ‰é’®
    3. æŸ¥çœ‹ç›¸å…³çŸ¥è¯†ç‰‡æ®µ
    """)

# åŠ è½½çŸ¥è¯†åº“çš„å‡½æ•°
@st.cache_resource
def load_knowledge_base():
    try:
        embeddings = OllamaEmbeddings(model="bge-m3")
        index_path = "./faiss_jinlei_index"
        
        if os.path.exists(index_path):
            vector_store = FAISS.load_local(
                index_path, 
                embeddings, 
                allow_dangerous_deserialization=True
            )
            st.sidebar.success("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸï¼")
            return vector_store
        else:
            st.sidebar.error(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_path}")
            return None
    except Exception as e:
        st.sidebar.error(f"âŒ åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
        return None

# åˆå§‹åŒ–åŠ è½½çŸ¥è¯†åº“
vector_store = load_knowledge_base()

# æŸ¥è¯¢è¾“å…¥åŒºåŸŸ
col1, col2 = st.columns([6, 1])
with col1:
    query = st.text_input(
        "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
        placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯å…­é“å·¥åºï¼Ÿ",
        key="query_input"
    )
with col2:
    st.write("")  # ä¸ºäº†å¯¹é½
    st.write("")
    search_button = st.button("ğŸ” æœç´¢", type="primary")

# å¤„ç†æŸ¥è¯¢
if search_button or query:
    if not query:
        st.warning("âš ï¸ è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹")
    elif vector_store is None:
        st.error("âŒ çŸ¥è¯†åº“æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥ç´¢å¼•æ–‡ä»¶")
    else:
        with st.spinner("æ­£åœ¨æœç´¢ä¸­..."):
            # æœç´¢ç›¸å…³æ–‡æ¡£
            results = vector_store.similarity_search(query, k=3)
            
            # æ˜¾ç¤ºç»“æœ
            st.subheader(f"ğŸ“‹ æœç´¢ç»“æœï¼ˆå…± {len(results)} æ¡ï¼‰")
            
            for i, doc in enumerate(results):
                with st.expander(f"ğŸ“„ ç»“æœ {i+1}", expanded=(i==0)):
                    st.markdown(f"**å†…å®¹ï¼š**")
                    st.markdown(doc.page_content)
                    
                    # æ˜¾ç¤ºå…ƒæ•°æ®
                    if doc.metadata:
                        st.markdown("**å…ƒæ•°æ®ï¼š**")
                        for key, value in doc.metadata.items():
                            st.markdown(f"- **{key}:** {value}")
            
            if not results:
                st.info("æœªæ‰¾åˆ°ç›¸å…³ç»“æœï¼Œè¯·å°è¯•å…¶ä»–æŸ¥è¯¢è¯ã€‚")

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.caption("ğŸ’¡ æç¤ºï¼šçŸ¥è¯†åº“åŸºäº 'å…­é“å·¥åº.docx' æ–‡æ¡£æ„å»º")
